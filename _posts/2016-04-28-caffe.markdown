---
layout: post
comments: true
title:  "Training and deploying deep learning networks with Caffe"
date:   2016-04-28 01:00:00
mathjax: true
---

"It is comparatively easy to make computers exhibit adult-level performance on intelligence tests or playing checkers, and difficult or impossible to give them the skills of a 1-year-old when it comes to perception and mobility." ~Hans Moravec

The content in this blog was written (excluding some minor recent additions) while I was at [AFRL](http://www.wpafb.af.mil/AFRL/) with the collaboration of [Sam Sakla](https://www.linkedin.com/in/wesamsakla), James Patrick, and [H. Scott Clouse](http://scottclouse.com) in my AFRL deep learning team. It was written for Caffe newbies and was approved for public released: 88ABW-2015-5479. The views expressed here are my opinion and do not reflect the opinion or position or endorsement of my employeer (current or previous).

* TOC
{:toc}

## Summary
[Caffe](http://caffe.berkeleyvision.org/) is a deep learning framework developed by the Berkeley Vision and Learning Center ([BVLC](http://caffe.berkeleyvision.org/)). It is written in C++ and CUDA C++ with Python and Matlab wrappers. Out of the box it is especially useful for convolutional neural networks. On a side note, I dislike the term *neural* because it gives the impression that it resembles a biological neuron -- let the neuroscientist worry about that and not the computer scientists (steping down the soapbox). There are various forks of the main Caffe [branch](https://github.com/BVLC/caffe/tree/master) that support [LSTM and image captioning](https://github.com/BVLC/caffe/pull/3948), [multinode training and CPU optimized](https://github.com/intelcaffe/caffe/) for devices, [GPU optimized](https://github.com/NVIDIA/caffe/) for devices, [detection and classification](https://github.com/rbgirshick/py-faster-rcnn), [segmentation](https://github.com/shelhamer/fcn.berkeleyvision.org), and [Spark](https://github.com/yahoo/CaffeOnSpark) compatible.

Vocabulary I use:

- weights (others call them kernels, feature extractors, filters, and paramters) 
- blob - a 4 dimensional data structure--a 4D tensor--that contains data, gradients, or weights (including bias)
- units (others call them neurons) - performs a non-linear transformation on a data blob
- feature maps (others call them channels)
- testing (others call it inference, classification, scoring, or deployment)

## Installation
On Ubuntu 14.04. Get dependencies:

~~~ bash
sudo apt-get update
sudo apt-get install -y git build-essential
sudo apt-get install -y libprotobuf-dev libleveldb-dev libsnappy-dev 
sudo apt-get install -y libopencv-dev libhdf5-serial-dev protobuf-compiler
sudo apt-get install -y --no-install-recommends libboost-all-dev
sudo apt-get install -y libgflags-dev libgoogle-glog-dev liblmdb-dev
sudo apt-get install -y libatlas-base-dev # not needed if installing MKL or OpenBLAS
~~~

Reasons for dependencies:

- boost: a c++ library. > Use some of its math functions and shared_pointer.
- glog,gflags provide logging & command line utilities. > Essential for debugging.
- leveldb, lmdb: database io for your program. > Need to know this for preparing your own data.
- protobuf: an efficient and flexible way to define data structure. > Need to know this for defining new layers.
- BLAS (Basic Linear Algebra Subprograms): operations like matrix multiplication, matrix addition, provided by MKL(INTEL), ATLAS, openBLAS, etc.

The Caffe installation guide [states](http://caffe.berkeleyvision.org/install_apt.html): Install "MKL for better CPU performance".

[Download](https://software.intel.com/en-us/articles/free_mkl) and install MKL. To download it, first [register](https://software.intel.com/en-us/articles/free_mkl) for a free community license and follow the installation instructions. Then

~~~ bash
echo 'source /opt/intel/bin/compilervars.sh intel64' >> ~/.bashrc
# alternatively edit <mkl_path>/mkl/bin/mklvars.sh with correct CPRO_PATH=<mkl_path>
# and 'source <mkl_path>/mkl/bin/mklvars.sh intel64' if file above doesn't exist
~~~

The next set of instructions are only needed if using Nvidia GPUs. The GPU device should have CUDA [compute capability](https://en.wikipedia.org/wiki/CUDA#Supported_GPUs) >= 3.0. Devices with compute capability < 3.0 may have to reduce CUDA thread numbers and batch sizes due to hardware constraints.

Note that in AWS, installing the Nvidia drivers will require additional steps. If using AWS, follow the steps in the [AWS section](http://rodriguezandres.github.io/2016/04/28/caffe/#aws) prior to installing the drivers.

~~~ bash
CUDA_VER=7.5 # modify to current version
VER_UPDATE=18 # modify to current version

# This first set of commands can be ignored if using a
# server with Nvidia drivers and CUDA already installed
CUDAFILE=cuda_$CUDA_VER\.$VER_UPDATE\_linux.run
wget http://developer.download.nvidia.com/compute/cuda/$CUDA_VER/Prod/local_installers/$CUDAFILE
chmod +x $CUDAFILE
mkdir nvidia_installers
./$CUDAFILE -extract=`pwd`/nvidia_installers
cd nvidia_installers
# Notes on installing drivers
# 1) it may be better to used the latest drivers from http://www.nvidia.com/Download/index.aspx
#    instead of the extracted one
# 2) if using AWS see the steps in the AWS section prior to installing the drivers
NVIDIA_DRIVERS=$(ls *NVIDIA*.run)
CUDA_INSTALLER=$(ls cuda*rel*.run)
CUDA_SAMPLES=$(ls cuda*samples*.run)
sudo ./$NVIDIA_DRIVERS # install nvidia drivers (ignore this is already installed w/AWS steps below)
sudo ./$CUDA_INSTALLER # install CUDA
sudo ./$CUDA_SAMPLES # install samples

# (Don't ignore these steps) Add CUDA files and libs to path
echo 'export PATH=/usr/local/cuda-'$CUDA_VER'/bin:$PATH' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=/usr/local/cuda-'$CUDA_VER'/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc

# The rest of these lines are OPTIONAL
rm $CUDAFILE 
cd ~/cuda/1_Utilities/deviceQuery
make
./deviceQuery # queries the GPU
nvidia-smi # returns GPU information
~~~

Downloading and installing Caffe. Note that in addition to the functionalities found in BVLC caffe, intelcaffe provides optimized CPU code for some CPU architectures and allows multinode training. Whether intelcaffe or BVLC caffe is used, the same steps and guidelines in this post apply. (Disclosure: I recently joined Intel where I learned about this Intel Caffe branch and therefore I'm including it here along with the content that was originally written at AFRL.)

~~~ bash
cd ~
source .bashrc
# For BVLC caffe use:
# git clone https://github.com/BVLC/caffe.git
# For intelcaffe use:
git clone https://github.com/intelcaffe/caffe.git 
cd caffe
echo "export CAFFE_ROOT=`pwd`" >> ~/.bashrc
cp Makefile.config.example Makefile.config

# Open Makefile.config and modify it (see comments in the Makefile)
vi Makefile.config
# To run on GPU using the cuDNN library, uncomment
# # USE_CUDNN := 1
# To run on CPU only and to avoid installing CUDA installers, uncomment
# # CPU_ONLY := 1
# To use MKL, replace atlas with mkl as follows
# (make sure that the BLAS_DIR and BLAS_LIB paths are correct)
# BLAS := mkl
# BLAS_DIR := /opt/intel/mkl/include
# BLAS_LIB := /opt/intel/mkl/lib/intel64
# To use MKL2017 DNN primitives as the default engine, uncomment
# # USE_MKL2017_AS_DEFAULT_ENGINE := 1
# and also (temporarily--this will become the default in future releases)
# # COMMON_FLAGS += -DUSE_MKL2017_NEW_API

# Make
NUM_CORES=$(grep 'core id' /proc/cpuinfo | sort -u | wc -l)
make -j $NUM_CORES 2>&1 | tee makelog.log # uses all the cores in make and saves output
# To save the output stream to file makestdout.log use this instead
# make -j $NUM_CORES 2>&1 | tee makestdout.log

# The steps below are OPTIONAL but highly recommended to use the python interface
sudo apt-get -y install gfortran python-dev python-pip
cd ~/caffe/python
for req in $(cat requirements.txt); do sudo pip install $req; done
sudo pip install scikit-image #depends on other packages
sudo ln -s /usr/include/python2.7/ /usr/local/include/python2.7
sudo ln -s /usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/ \
  /usr/local/include/python2.7/numpy
echo 'sudo ln /dev/null /dev/raw1394' >> ~/.bashrc
make pycaffe -j NUM_CORES
echo 'export PYTHONPATH=$CAFFE_ROOT/python' >> ~/.bashrc

# The steps below are OPTIONAL to test caffe (recommended 1st time only)
make test -j $NUM_CORES
make runtest #"YOU HAVE <some number> DISABLED TESTS" output is OK

# The step below is OPTIONAL
# it disables cam hardware OpenCV driver; alternatively, the user can skip this
# and ignore the libdc1394 error that would occassionally appeared
echo 'export sudo ln /dev/null /dev/raw1394' >> ~/.bashrc
~~~

## Dataset preparation
Training and validation in Caffe is performed with the data stored in a set of Lightning Memory-Mapped Databases ([lmdb](http://en.wikipedia.org/wiki/Lightning_Memory-Mapped_Database)). The training/validation can be performed on data that's in common image formats or HDF5, however, incurring a loss of efficiency.

In order to use Caffe's tools to convert datasets to lmdbs the following is required:

- A folder with the images
- The output folders, e.g., mydataset_train_lmdb, must be non-existent
- A text file with the image file names and corresponding labels, e.g., "train.txt" looks like

~~~ bash
img3423.jpg 2
img3424.jpg 13
img3425.jpg 8
...
~~~

For example, the [create_label_file.py](https://github.com/RodriguezAndres/Kaggle-dogs-vs-cats/blob/master/create_label_file.py) script creates a training and validation text file for [Kaggle's Dog vs Cats](https://www.kaggle.com/c/dogs-vs-cats/data) competition.

Note that in testing we assume that the labels are missing. If labels are available these same steps can be applied to prepare an lmdb test dataset.

<h4>Preparing data with 3 channels (e.g., RGB images)</h4>
The example below (based on [this](http://caffe.berkeleyvision.org/gathered/examples/imagenet.html)) produces a training and a validation lmdb, and therefore requires two text files, train.txt and val.txt. It runs from the `$CAFFE_ROOT` directory. Note that in this example it assumes the training and validation images are in the same folder.

~~~ bash
#!/usr/bin/env sh
# Create the lmdb inputs
TRAIN_DATA_ROOT=/home/ubuntu/data/train # folder containing the training and validation images
TEXT=/home/ubuntu/data # folder containing the text files 
OUTPUT=/home/ubuntu/data # folder for the lmdb datasets
TOOLS=build/tools

# Set RESIZE=true to resize the images to 256x256
RESIZE=false
if $RESIZE; then
  RESIZE_HEIGHT=256
  RESIZE_WIDTH=256
else
  RESIZE_HEIGHT=0
  RESIZE_WIDTH=0
fi

echo "Creating train lmdb..."

GLOG_logtostderr=1 $TOOLS/convert_imageset \
    --resize_height=$RESIZE_HEIGHT \
    --resize_width=$RESIZE_WIDTH \
    --shuffle \
    $TRAIN_DATA_ROOT/ \
    $DATA/train.txt \
    $OUTPUT/mydataset_train_lmdb

echo "Creating val lmdb..."

GLOG_logtostderr=1 $TOOLS/convert_imageset \
    --resize_height=$RESIZE_HEIGHT \
    --resize_width=$RESIZE_WIDTH \
    --shuffle \
    $TRAIN_DATA_ROOT/ \
    $DATA/val.txt \
    $OUTPUT/mydataset_val_lmdb

echo "Done."
~~~

Computing the mean image in lmdb dataset:

~~~ bash
#!/usr/bin/env sh
# Compute the mean image in lmdb dataset
OUTPUT=/home/ubuntu/data # folder for the lmdb datasets and output for mean image
TOOLS=build/tools

$TOOLS/compute_image_mean $OUTPUT/mydataset_train_lmdb \
  $OUTPUT/train_mean.binaryproto

$TOOLS/compute_image_mean $OUTPUT/mydataset_val_lmdb \
  $OUTPUT/val_mean.binaryproto

echo "Done."
~~~

Viewing the mean image

~~~ python
import caffe
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.cm as cm
%matplotlib inline

blob = caffe.proto.caffe_pb2.BlobProto()
data = open('/home/ubuntu/data/train_mean.binaryproto','rb').read()
blob.ParseFromString(data)
arr = np.array(caffe.io.blobproto_to_array(blob))[0,:,:,:].mean(0)
plt.imshow(arr, cmap=cm.Greys_r)
plt.show()
~~~

<h4>Preparing data with various channels</h4>
Gray scale images (1-channel), RADAR images (2-channels), videos (4 channels), image+depth (4 channels), vibrometry (1 channel), and spectrograms (1-channel) required a wrapper in order to set the lmdb dataset (see [this blog script](https://github.com/BVLC/caffe/issues/1698#issuecomment-70211045) as a guide).

## Data Layer
The material in this section is based on [this](http://caffe.berkeleyvision.org/tutorial/layers.html) and [this](http://vision.stanford.edu/teaching/cs231n/slides/caffe_tutorial.pdf) tutorials. Data enters Caffe through data layers: they lie at the bottom of nets. Data can come from efficient databases (LevelDB or LMDB), directly from memory, or, when efficiency is not critical, from files on disk in HDF5 or common image formats.

Common input preprocessing (mean subtraction, scaling, random cropping, and mirroring) is available by specifying `transform_params` (not supported in all data types, e.g., HDF5). If the required data transformations are performend beforehand, then there is no need to use this option in the data layer.

Note that it is common but not required to have the same name for the layer and the blob coming out of the layer, i.e., in the prototxt files in each layer `name` and `top` are usually the same.

<h4>Data</h4>
LMDB and LevelDB database formats can be efficiently process as input data. Only good for 1-of-k classification. Use this if possible.

Parameters

- Required
  - `source`: the name of the directory containing the database
  - `batch_size`: the number of inputs to process at one time
- Optional
  - `backend` [default LEVELDB]: choose whether to use a LEVELDB or LMDB
  - `rand_skip`: skip this number of inputs at the beginning; maybe useful for async sgd

In this example the images are cropped, mirrored, and have the mean subtracted.

~~~ bash
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: 1 # 1 = on, 0 = off
    # crop a `crop_size` x `crop_size` patch:
    # - at random during training
    # - from the center during testing
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "examples/imagenet/ilsvrc12_train_lmdb"
    batch_size: 32
    backend: LMDB
  }
}
~~~

<h4>MemoryData</h4>
The memory data layer reads data directly from memory, without copying it. In order to use it, one must call `MemoryDataLayer::Reset` (from C++) or `Net.set_input_arrays` (from Python) in order to specify a source of contiguous data (as 4D row major array), which is read one batch-sized chunk at a time.

This is the most efficient method as it assumes that data is already in memory. Otherwise, it can be slow as it requires manually copying the data into memory prior to using it.

Parameters

- Required
  - `batch_size`, `channels`, `height`, `width`: specify the size of input chunks to read from memory 

~~~ bash
layers {
  name: "data"
  type: MEMORY_DATA
  top: "data"
  top: "label"
  memory_data_param {
   batch_size: 32
   channels: 3
   height: 227
   width: 227
  }
 transform_param {
    crop_size: 227
    mirror: true
    mean_file: "mean.binaryproto"
  }
~~~

<h4>HDF5Data</h4>
Reads arbitrary data from HDF5 files. Good for any task but only uses FP32 and FP64 data (not uint8), so image data will be huge. Does not allow `transform_param`. Only use this if you have to.

Parameters

- Required
  - source: the name of the file to read from
  - batch_size

~~~ bash
layer {
  name: "data"
  type: "HDF5_DATA"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "examples/hdf5_classification/data/train.txt"
    batch_size: 32
    backend: LMDB
  }
}
~~~

<h4>HDF5DataOutput</h4>
The HDF5 output layer performs the opposite function of the other layers in this section: it writes its input blobs to disk.


<h4>ImageData</h4>
Get images and labels directly from image files.


<h4>WindowData</h4>
Made for detection. Read windows from image files class labels.

<h4>DummyData</h4>
Used in debugging and can be used in benchmarking forward and backward times

Example based on [this](https://github.com/BVLC/caffe/blob/master/examples/pycaffe/linreg.prototxt) one.

~~~ bash
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "constant"
      value: 0.01
    }
    shape { dim: 32 dim: 3 dim: 224 dim: 224 }
  }
}
layer {
  name: "data"
  type: "DummyData"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "constant"
    }
    shape { dim: 32 }
  }
}
~~~


## Training
Training requires:

- train_val.prototxt: defines the network architecture, initialization parameters, and local learning rates
- solver.prototxt: defines optimization/training parameters and serves as the actual file that's called to train a deep network
- (deploy.prototxt: actually this is used only in testing; is similar to train_val.prototxt but without the local learning rates, initialization values, and data layer)

Note that it is common but not required to have the same name for the layer and the blob coming out of the layer, i.e., in the prototxt files in each layer `name` and `top` are usually the same.


A description of what each layer does can be found [here](http://caffe.berkeleyvision.org/tutorial/layers.html). Initialization parameters are extremely important; they are set [here](https://github.com/BVLC/caffe/blob/master/include/caffe/filler.hpp here); some [tips](http://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization) worth mentioning:

- weight_filter initialization (for ReLU neurons, MSRAFiller is usually better than xavier which is usually better than gaussian; note for MSRAFiller and xavier, there is no need to manually specify std)
  - gaussian: samples weights from N(0,std)
  - xavier: samples weights from uniform distribution U(-a,a), where a=sqrt(3/fan_in), where fan_in are the number of incoming neurons 
  - MSRAFiller: samples weights from normal distribution N(0,a), where a=sqrt(2/fan_in)
- base_lr: initial learning rate ( default:.01, change to a smaller number if getting NAN loss in training )
- lr_mult for the bias is usually set to 2x the lr_mult for the non-bias weights

LeNet example: [lenet_train_test.prototxt](https://github.com/BVLC/caffe/blob/master/examples/mnist/lenet_train_test.prototxt), [deploy.prototxt](https://github.com/BVLC/caffe/blob/master/examples/mnist/lenet.prototxt), and solver.prototxt described below (comments about what each variable means are included):

solver.prototxt

~~~ bash
# The train/validation net protocol buffer definition, i.e., the training architecture
net: "examples/mnist/lenet_train_test.prototxt"

# Note: 1 iteration = 1 forward pass over all the images in one batch

# Carry out a validation test every 500 training iterations.
test_interval: 500 

# test_iter specifies how many forward passes the validation test should carry out
#  a good number is num_val_imgs / batch_size (see batch_size in Data layer in phase TEST in train_test.prototxt)
test_iter: 100 

# The base learning rate, momentum and the weight decay of the network.
base_lr: 0.01
momentum: 0.9 
weight_decay: 0.0005

# We want to initially move fast towards the local minimum and as we approach it, we want to move slower
# To this end, there are various learning rates policies available:
#  fixed: always return base_lr.
#  step: return base_lr * gamma ^ (floor(iter / step))
#  exp: return base_lr * gamma ^ iter
#  inv: return base_lr * (1 + gamma * iter) ^ (- power)
#  multistep: similar to step but it allows non uniform steps defined by stepvalue
#  poly: the effective learning rate follows a polynomial decay, to be zero by the max_iter: return base_lr (1 - iter/max_iter) ^ (power)
#  sigmoid: the effective learning rate follows a sigmod decay: return base_lr * ( 1/(1 + exp(-gamma * (iter - stepsize))))
lr_policy: "step"
gamma: 0.1 
stepsize: 10000 # Drop the learning rate in steps by a factor of gamma every stepsize iterations

# Display every 100 iterations
display: 100 

# The maximum number of iterations
max_iter: 10000

# snapshot intermediate results, i.e., every 5000 iterations it saves a snapshot of the weights
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet_multistep"

# solver mode: CPU or GPU
solver_mode: CPU
~~~

Train the network:

~~~ bash
# The name of the output file (aka the trained weights) is in solver.prototxt
$CAFFE_ROOT/build/tools/caffe train -solver solver.prototxt
~~~

If using GPU, to specify a device or a group of devices use the `-gpu <gpu ids>` argument, where `<gpu ids>` can range from `0` to `numGPUs-1`. This works in training, fine-tuning, timing, or testing. The following examples are for training but the same applies in fine-tuning, timing, or testing.

~~~ bash
# train on GPU device 2
./build/tools/caffe train -solver examples/mnist/lenet_solver.prototxt -gpu 2
# train on GPUs devices 0 & 1 (doubles the batch size)
./build/tools/caffe train -solver examples/mnist/lenet_solver.prototxt -gpu 0,1
# train on all GPUs on node (multiplies batch size by number of GPU devices)
./build/tools/caffe train -solver examples/mnist/lenet_solver.prototxt -gpu all

# side note: each GPU device can be diagnosed
./build/tools/caffe devices_query -gpu 2
~~~

Training will produce two files:

- *\<somename_numiter\>.caffemodel*: weights of the architecture to be used in testing
- *\<somename_numiter\>.solverstate*: used if training dies (e.g., power outage) to resume training from current iteration

To train the network and plot the validation accuracy or loss vs iterations:

~~~ bash
#CHART_TYPE=[0-7]
#  0: Test accuracy  vs. Iters
#  1: Test accuracy  vs. Seconds
#  2: Test loss  vs. Iters
#  3: Test loss  vs. Seconds
#  4: Train learning rate  vs. Iters
#  5: Train learning rate  vs. Seconds
#  6: Train loss  vs. Iters
#  7: Train loss  vs. Seconds
CHART_TYPE=0
$CAFFE_ROOT/build/tools/caffe train -solver solver.prototxt 2>&1 | tee logfile.log
python $CAFFE_ROOT/tools/extra/plot_training_log.py.example $CHART_TYPE name_of_plot.png logfile.log
~~~

Dropout and Dropconnect:

- Dropconnect does not exist in the main Caffe branch as the benefits are marginal
- Dropout can be implemented in a fully connected layer as

~~~ bash
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }   
    bias_filler {
      type: "constant"
      value: 1
    }   
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5 
  }
}
~~~

Measuring forward and backward propagation time (not weight updates):

~~~ bash
# Computes 50 iterations and returns forward, backward, and total time and the average
# note that the training samples and mean.binaryproto may be required or
# alternatively, use dummy variables
NUMITER=50
$CAFFE_ROOT/build/tools/caffe time --model=train_val.prototxt -iterations $NUMITER
~~~

<h4>Model Zoo</h4>
The [Caffe Model Zoo](https://github.com/BVLC/caffe/wiki/Model-Zoo) is a collection of trained deep learning models and/or prototxt files used for a variety of tasks. These models can be used in fine-tuning or testing.


## Fine-tuning
Recyle the layer definition prototxt file and made the following two changes:

1. Change the data layer to include the new data:

~~~ bash
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "newdata_lmdb" #CHANGED THIS LINE TO THE NEW DATASET WITH ONLY TWO CLASSES
    batch_size: 64
    backend: LMDB
  }
}
~~~

2. Change the last layer, e.g., "fc2-ft" (note: in testing, make this same change to the deploy.prototxt file)

~~~ bash
layer {
  name: "ip2-ft" #CHANGED THIS LINE
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2-ft" #CHANGED THIS LINE
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2 #CHANGED THIS LINE TO THE NUMBER OF CLASSES IN NEW DATASET
    bias_filler {
      type: "constant"
    }
  }
}
~~~

Invoke caffe, i.e., train or, more precisely, fine-tune:

~~~ bash
#From the command line on $CAFFE_ROOT
./build/tools/caffe train -solver name_of_solver.prototxt -weights already_trained_binary_model.caffemodel
~~~

<h4>Fine-tuning guidelines</h4>
- Learn the last layer first (earlier layer weights won't change very much in fine-tuning)
  - Caffe layers have local learning rates: `lr_mult`
  - Freeze all but the last layer for fast optimization, i.e., `lr_mult=0`
  - Stop if good enough or keep fine-tuning other layers
  - This will speed up training times
- Alternatively you could leave all learning rates as they are and increase the last two layers
  - Last layer by 10x
  - Second to last by 5x
- Reduce the learning rate
  - Drop the initial learning rate (in the solver_file.prototxt) by 10x or 100x

<h4>What happens under the hood</h4>
- Creates a new network
- Copy the previous weights to initialized network weights
- Solves the usual way
(see [example](http://caffe.berkeleyvision.org/gathered/examples/finetune_flickr_style.html))

## Testing
To classify an image (or signal) or set of images you need:

- Image(s)
- Network architecture
- Network weights

The python interface is very handy in testing. The modules used for testing are Classifier, load_image and predict:

- net = caffe.Classifier
  - INPUTS: architecture (model_file) and weights (pretrained_file)
  - Optional: image_dims; mean=None (subtraction switched on by giving a mean array--usually mean of the training images); input_scale=None; raw_scale=None (multiplies the feature scale from the input [0,1] to [0,raw_scale]; channel_swap=None
  - RETURNS: network

- caffe.io.load_image
  - INPUT: image
  - RETURNS: image formatted for Caffe

- prediction = net.predict
  - INPUT: a list of H \\( \times \\) W \\( \times \\) K arrays, i.e., a list of images
  - Optional: oversample=True (crops 10 images--center, corners, mirrors; if false only crops center)
  - RETURNS: Classification probabilities of inputs as a list of list

Example script to test network (type: "python [classify_example.py](https://github.com/RodriguezAndres/CaffeTutorial/blob/master/classify_example.py)" to run):
- import the required modules
- ensure that the pretrained model has been downloaded
- specify CPU/GPU mode,
- load pre-trained deep net and specify any pre-processing on the input

~~~ python
import numpy as np

# Make sure that caffe is on the python path:
import sys 
CAFFE_ROOT = '/home/ubuntu/caffe/' # CHANGE THIS LINE TO YOUR Caffe PATH
sys.path.insert(0, CAFFE_ROOT + 'python')

import caffe

# Set the right path to your model definition file, pretrained model weights,
# and the image you would like to classify.
MODEL_FILE = CAFFE_ROOT + 'models/bvlc_reference_caffenet/deploy.prototxt'
PRETRAINED = CAFFE_ROOT + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel' #Weights to be used w/MODEL_FILE
IMAGE_FILE1 = CAFFE_ROOT + 'examples/images/cat.jpg'
IMAGE_FILE2 = CAFFE_ROOT + 'examples/images/fish-bike.jpg'

# Download weight file if not found
import os
if not os.path.isfile(PRETRAINED):
    print("Downloading pre-trained CaffeNet model...")
    os.system('../scripts/download_model_binary.py ../models/bvlc_reference_caffenet')

# Use GPU or CPU
caffe.set_mode_cpu()
#caffe.set_mode_gpu()

# Load network
# Note arguments to preprocess input
#  mean subtraction switched on by giving a mean array
#  input channel swapping takes care of mapping RGB into the reference ImageNet model's BGR order
#  raw scaling multiplies the feature scale from the input [0,1] to the ImageNet model's [0,255]
net = caffe.Classifier(MODEL_FILE, PRETRAINED,
                       mean=np.load(CAFFE_ROOT + 'python/caffe/imagenet/ilsvrc_2012_mean.npy').mean(1).mean(1),
                       channel_swap=(2,1,0),
                       raw_scale=255,
                       image_dims=(256, 256))
# Alternatively, the above could have been written as:
#net = caffe.Classifier(MODEL_FILE, PRETRAINED)
#net.transformer.set_mean('data', np.load(CAFFE_ROOT + 'python/caffe/imagenet/ilsvrc_2012_mean.npy').mean(1).mean(1))
#net.transformer.set_raw_scale('data', 255)  # reference model operates on [0,255] range instead of [0,1]
#net.transformer.set_channel_swap('data', (2,1,0))  # the reference model has channels in BGR order instead of RGB

input_image1 = caffe.io.load_image(IMAGE_FILE1)
input_image2 = caffe.io.load_image(IMAGE_FILE2)
input_images = [input_image1, input_image2]

# Classify image
prediction = net.predict(input_images)  # predict takes any number of images, and formats them for the Caffe net automatically
print 'predicted classes:', prediction[0].argmax(), prediction[1].argmax()

### The steps below are OPTIONAL ###
# View input_image1
plt.imshow(input_image1)

# View the probabilities of all the classes for input_image1 as a bar chart
plt.plot(prediction[0])

# Time the full pipeline classification for 1 image w/oversampling
timeit net.predict([input_image1])

# Time the only forward pass classification for 1 image by resizing/oversampling before forward pass
#   Resize the image to the standard (256, 256) and oversample net input sized crops.
input_oversampled = caffe.io.oversample([caffe.io.resize_image(input_image1, net.image_dims)], net.crop_dims)
#   'data' is the input blob name in the model definition, so we preprocess for that input.
caffe_input = np.asarray([net.transformer.preprocess('data', in_) for in_ in input_oversampled])
#  forward() takes keyword args for the input blobs with preprocessed input arrays.
timeit net.forward(data=caffe_input)
~~~

If using a folder with many images, just replace input_images as follows (everything else stays the same)

~~~ python
IMAGE_FOLDER = '/path_to_folder_w_images/'
import os
images = os.listdir(IMAGES_FOLDER)
input_images = [ caffe.io.load_image(IMAGES_FOLDER + im) for im in images ]
~~~

Note that the entire test set may not fit in memory, so in same architectures, it may be better to do the predictions in batches of (say) 100.

Testing from the command line seems to be less flexible and using Python is my preferred choice. Note that the file with the model should have a 'phase: TEST' in the data layer in order to test the model.

~~~ bash
#./build/tools/caffe test -model <model_filename> -weights <somename_numiter>.caffemodel -iterations <how many iteratiosn/mini-batches to train>
#  -iterations: to use all val imgs use iter = numValImgs / batchSize
./build/tools/caffe test -model models/bvlc_reference_caffenet/train_val.prototxt -weights models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel -iterations 50
~~~


## Feature extractor and visualization
In a convolutional layer the weights from one layer to the next can be represented by a blob which is four-dimensional tensor: output_feature_maps \\( \times \\) height \\( \times \\) width \\( \times \\) input_feature_maps (feature_maps AKA channels). There are two options for using networks trained in Caffe as feature extractors: The first option (highly recommended) is to use the Python API, and the second option is to use the native C++ utility that ships with Caffe.

<h4>Using the Python API</h4>

~~~ python
# Assumes that the "net = caffe.Classifier" module has been called as in the script above
# Retrieve details of the network’s layers and shapes
[(k, v.data.shape) for k, v in net.blobs.items()]

# Retrieve parameters of the network’s layers
[(k, v[0].data.shape) for k, v in net.params.items()]

# Retrieve the features in the last fully connected layer prior to outputting class probabilities
feat = net.blobs['fc7'].data[4]

# Retrieve size/dimensions of the array
feat.shape
~~~

Example

~~~ python
# Assumes that the "net = caffe.Classifier" module has been called
# and data has been formatted as in the example above

# View a list of the network layer outputs and their dimensions
[(k, v.data.shape) for k, v in net.blobs.items()]

# VISUALIZE DATA DEFINITION 
# take an array of shape (n, height, width) or (n, height, width, channels)
# and visualize each (height, width) thing in a grid of size approx. sqrt(n) by sqrt(n)
def vis_square(data, padsize=1, padval=0):
    data -= data.min()
    data /= data.max()
    
    # force the number of filters to be square
    n = int(np.ceil(np.sqrt(data.shape[0])))
    padding = ((0, n ** 2 - data.shape[0]), (0, padsize), (0, padsize)) + ((0, 0),) * (data.ndim - 3)
    data = np.pad(data, padding, mode='constant', constant_values=(padval, padval))
    
    # tile the filters into an image
    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, data.ndim + 1)))
    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])
    
    plt.imshow(data)

    # the parameters are a list of [weights, biases]

# VISUALIZE THE WEIGHTS OF THE 1ST CONV LAYER
plt.rcParams['figure.figsize'] = (25.0, 20.0)
filters = net.params['conv1'][0].data
vis_square(filters.transpose(0, 2, 3, 1))

# VISUALIZE THE FEATURE MAPS AFTER 1ST CONV LAYER
feat = net.blobs['conv1'].data[0,:96]
vis_square(feat, padval=1)
net.blobs['conv1'].data.shape

# VISUALIZE THE FEATURE MAPS AFTER 2ND CONV LAYER
feat = net.blobs['conv2'].data[0]
vis_square(feat, padval=1)
net.blobs['conv1'].data.shape

# VISUALIZE THE FEATURE MAPS AFTER 2ND POOL LAYER
feat = net.blobs['pool2'].data[0,:256] # change 256 to number of pool outputs
vis_square(feat, padval=1)
net.blobs['conv1'].data.shape

# VISUALIZE THE NEURON ACTIVATIONS FOR THE 2ND FULLY-CONNECTED LAYER
feat = net.blobs['ip2'].data[0]
plt.plot(feat.flat)
plt.legend()
plt.show()
~~~

<h4>Using the C++ Utility</h4>
Ensure that Caffe has been successfully installed and the model params downloaded

~~~ bash
# Download model params
scripts/download_model_binary.py models/bvlc_reference_caffenet

# Make a temporary folder
mkdir examples/_temp

# Generate a list of the files to process
# We’re going to use the images that ship with caffe
find `pwd`/examples/images -type f -exec echo {} \; > examples/_temp/temp.txt

# Add a 0 to the end of each line
#  input data structures expect labels after each image file name
sed "s/$/ 0/" examples/_temp/temp.txt > examples/_temp/file_list.txt

# Get the mean of trn set to subtract it from imgs
./data/ilsvrc12/get_ilsvrc_aux.sh

# Copy and modify the network definition to use it's datalayer to load and resize the images:
cp examples/feature_extraction/imagenet_val.prototxt examples/_temp

# Extract features
./build/tools/extract_features.bin models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel \
    examples/_temp/imagenet_val.prototxt fc7 examples/_temp/features 10 lmdb

# Remove features
rm -rf examples/_temp/features/
~~~

Above, the name of the feature blob that is extracted is ''fc7'', which represents the highest level feature of the reference model. Alternatively, other layers can be used as well, such as ''conv5'' or ''pool3''. The last parameter above (10 lmdb) is the mini-batch size. The features are stored to LevelDB `examples/_temp/features`, ready for access by some other code.

Upon issuing the command, if the following error is received, "Check failed: status.ok() Failed to open leveldb examples/_temp/features", it's because the directory ''examples/_temp/features'' has been created the last time the command was issued. Remove directory and run again.


## Examples
<h4>LeNet on MNIST</h4>
The purpose of this section is to experiment with preparing a dataset, training a model, timing the model, and using multiple GPUs in one node. The content comes from [here](http://caffe.berkeleyvision.org/gathered/examples/mnist.html) and [here](http://caffe.berkeleyvision.org/tutorial/interfaces.html).

Preparing datasets

~~~ bash
cd $CAFFE_ROOT
./data/mnist/get_mnist.sh # downloads MNIST dataset
./examples/mnist/create_mnist.sh # creates dataset in LMDB format
~~~

Training dataset

~~~ bash
# Reduce the number of iterations from 10K to 1K to quickly run through this example
sed -i 's/max_iter: 10000/max_iter: 1000/g' examples/mnist/lenet_solver.prototxt
# CPU or GPU usage is defined in the solver.prototxt file
./build/tools/caffe train -solver examples/mnist/lenet_solver.prototxt
#./build/tools/caffe train -solver examples/mnist/lenet_solver.prototxt -gpu all # to use all GPUs
~~~

Timing the forward + backward propogations (not including weight updates)

~~~ bash
./build/tools/caffe time --model=examples/mnist/lenet_train_test.prototxt -iterations 50 # runs on CPU
#./build/tools/caffe time --model=examples/mnist/lenet_train_test.prototxt -gpu 0 -iterations 50 # uses GPU 0
~~~

Testing the trained model. In this example it is tested in the validation test. In practice, it should be tested with a different dataset using the formate below or the format explained [above](http://rodriguezandres.github.io/2016/04/28/caffe/#testing).

~~~ bash
#./build/tools/caffe test -model <model_filename> -weights <somename_numiter>.caffemodel -iterations <how many iteratiosn/mini-batches to train>
# the file with the model should have a 'phase: TEST' in order to test the model
./build/tools/caffe test -model examples/mnist/lenet_train_test.prototxt -weights examples/mnist/lenet_iter_1000.caffemodel -iterations 50
~~~


<h4>Dogs vs Cats</h4>
Get an account with [Kaggle](https://www.kaggle.com/) and download the [data](https://www.kaggle.com/c/dogs-vs-cats/data). Note that you cannot just do wget because you have to login to Kaggle. Login to Kaggle, download data, and transfer it to your machine

Unzip [dogvscat.zip](https://github.com/RodriguezAndres/Kaggle-dogs-vs-cats/blob/master/dogvscat.sh) and execute the `dogvscat.sh` script (contained in the zip file and shown below for convenience).

~~~ bash
#!/usr/bin/env sh
CAFFE_ROOT=/home/ubuntu/caffe
mkdir dogvscat
DOG_VS_CAT_FOLDER=/home/ubuntu/dogvscat

cd $DOG_VS_CAT_FOLDER
## Download datasets (requires first a login)
#https://www.kaggle.com/c/dogs-vs-cats/download/train.zip
#https://www.kaggle.com/c/dogs-vs-cats/download/test1.zip

# Unzip train and test data
sudo apt-get -y install unzip
unzip train.zip -d .
unzip test1.zip -d .

# Format data
python create_label_file.py # creates 2 text files with labels for training and validation
./build_datasets.sh # build lmdbs

# Download ImageNet pretrained weights (takes ~20 min)
$CAFFE_ROOT/scripts/download_model_binary.py $CAFFE_ROOT/models/bvlc_reference_caffenet 

# Fine-tune weights in the AlexNet architecture (takes ~100 min)
$CAFFE_ROOT/build/tools/caffe train -solver $DOG_VS_CAT_FOLDER/dogvscat_solver.prototxt \
    -weights $CAFFE_ROOT/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel 

# Classify test dataset
cd $DOGVSCAT_FOLDER
python convert_binaryproto2npy.py
python dogvscat_classify.py # Returns prediction.txt (takes ~30 min)

# A better approach is to train five AlexNets w/init parameters from the same distribution,
# fine-tune those five, and compute the average of the five networks
~~~

- I submitted my results to Kaggle and got a score of 0.97566 accuracy (which would have placed 15th out of 215 had I competed).

<h4>PASCAL VOC Classification</h4>
Unzip [voc2012.zip](https://github.com/RodriguezAndres/Pascal-VOC-2012/blob/master/voc2012.zip) and execute the `voc2012.sh` script (contained in the zip file and shown below for convenience). Type `sudo chmod 700 *.sh` to make sure the scripts can be executed. It trains and runs AlexNet.

~~~ bash
#!/usr/bin/env sh

# Copy and unzip voc2012.zip (it contains this file) then run this file. But first
#  change paths in: voc2012.sh; build_datasets.sh; solvers/*; nets/*; classify.py

# As you run various files, you can ignore the following error if it shows up:
#  libdc1394 error: Failed to initialize libdc1394

# set Caffe root directory
CAFFE_ROOT=$CAFFE_ROOT
VOC=/home/ubuntu/voc2012

chmod 700 *.sh

# Download datasets or copy from /files/vol03/projects/Caffe/data/PASCAL_VOC/
# Details: http://host.robots.ox.ac.uk/pascal/VOC/voc2012/index.html#devkit
if [ ! -f VOCtrainval_11-May-2012.tar ]; then
  wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar
fi
# VOCtraival_11-May-2012.tar contains the VOC folder with:
#  JPGImages: all jpg images
#  Annotations: objects and corresponding bounding box/pose/truncated/occluded per jpg
#  ImageSets: breaks the images by the type of task they are used for
#  SegmentationClass and SegmentationObject: segmented images (duplicate directories)
tar -xvf VOCtrainval_11-May-2012.tar

# Run python scripts to create labeled text files
python create_labeled_txt_file.py
 
# Execute shell script to create training and validation lmdbs
# Note that LMDB directories w/the same name cannot exist prior to creating them
./build_datasets.sh
 
# Execute following command to download caffenet pre-trained weights (takes ~20 min)
#  if weights exist already then the command is ignored
$CAFFE_ROOT/scripts/download_model_binary.py $CAFFE_ROOT/models/bvlc_reference_caffenet
 
# Fine-tune weights in the AlexNet architecture (takes ~60 min)
# you can also chose one of six solvers: pascal_solver[1-6].prototxt
$CAFFE_ROOT/build/tools/caffe train -solver $VOC/solvers/voc2012_solver.prototxt \
  -weights $CAFFE_ROOT/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel

# The lines below are not really needed; they served as examples on how to do some tasks

# Test against voc2012_val_lmbd dataset (name of lmdb is the model under PHASE: test)
 $CAFFE_ROOT/build/tools/caffe test -model $VOC/nets/voc2012_train_val_ft678.prototxt \
   -weights $VOC/weights_iter_5000.caffemodel -iterations 116

# Classify validation dataset: returns a file w/the labels of the val dataset
#  but it doesn't report accuracy (that would require some adjusting of the code)
python convert_binaryproto2npy.py
mkdir results
python cls_confidence.py
python average_precision.py

# Note to submit results to the VOC scoreboard, retrain NN using the trainval set
# and test on the unlabeled test data provided by VOC

# A better approach is to train five CNNs w/init parameters from the same distribution,
# fine-tune those five, and compute the average of the five networks
~~~

**Additional VOC information** (in case the reader is interested in learning more about VOC):

- PASCAL VOC [datasets](http://host.robots.ox.ac.uk/pascal/VOC/)
- To compare methods or design choices
  - use the entire VOC2007 data, where all annotations (including test annotations) are available
  - report cross-validation results using VOC2012 "trainval" set alone (no test annotations are provided from 2008 to 2012)
  - most common metric is [average precision (AP)](https://makarandtapaswi.wordpress.com/2012/07/02/intuition-behind-average-precision-and-map/): area under the precision/recall curve
- VOC 2012 Data Summary
  - In 2008, there was a new dataset and each year more data was added. Therefore it is common to see published results in VOC2007 and VOC2012 (or VOC2011--no additional data for the classification and detection task between 2011 and 2012)
  - 20 classes
  - Training: 5,717 images, 13,609 objects
  - Validation: 5,823 images, 13,841 objects
  - Testing: 10,991 images


## AWS
<h4>Installing Nvidia drivers</h4>
If using Nvidia GPUs, the appropriate driver's need to be installed. The following steps are based on [this](http://tleyden.github.io/blog/2014/10/25/cuda-6-dot-5-on-aws-gpu-instance-running-ubuntu-14-dot-04/) blog. Note that two reboots are required. After following these steps, installation can continue using the steps [above](http://rodriguezandres.github.io/2016/04/28/caffe/#installation) ignoring the installation of Nvidia drivers in those steps.

~~~ bash
sudo apt-get install linux-image-extra-virtual
sudo reboot
# after reboot, disable nouveau
sudo echo 'blacklist nouveau' >> /etc/modprobe.d/blacklist-nouveau.conf
sudo echo 'blacklist lbm-nouveau' >> /etc/modprobe.d/blacklist-nouveau.conf
sudo echo 'options nouveau modeset=0' >> /etc/modprobe.d/blacklist-nouveau.conf
sudo echo 'alias nouveau off' >> /etc/modprobe.d/blacklist-nouveau.conf
sudo echo 'alias lbm-nouveau off' >> /etc/modprobe.d/blacklist-nouveau.conf
# disable the Kernel nouveau
echo options nouveau modeset=0 | sudo tee -a /etc/modprobe.d/nouveau-kms.conf
sudo update-initramfs -u
sudo reboot
# get Kernel source
sudo apt-get install linux-source
sudo apt-get install linux-headers-$(uname -r)
# Download the latests drivers from http://www.nvidia.com/Download/index.aspx
# (as of May 11, 2016 for the g2 instances with GRID K520 GPUs use the version below)
DRIVER_VERSION=361.42 # update this line with the latests driver from link above
NVIDIA_DRIVERS=NVIDIA-Linux-x86_64-$DRIVER_VERSION.run
wget http://us.download.nvidia.com/XFree86/Linux-x86_64/$DRIVER_VERSION/$NVIDIA_DRIVERS
sudo ./$NVIDIA_DRIVERS
~~~

<h4>Mounting a volume to an EC2 instance</h4>
Create a volume (or select existing volume) and attach it to EC2 instance. New volumes are raw block devices, and user needs to create a file system on them before user can mount and use them.

~~~ bash
### Once the volume is attached via the EC2 console, it can be mounted as follow ###
lsblk # Find the name of the device attached volume (e.g., xvdf means device_name is /dev/xvdf)

sudo file -s <device_name> # check that the volume is empty: only returns "device_name: data" 
sudo mkfs -t ext4 <device_name> # WARNING: only do this step if volume is empty (it will delete existing data)
sudo mkdir work_folder_name # mame the folder (e.g., data, work, etc)
sudo mount <device_name> work_folder_name
sudo chown -R ubuntu:ubuntu work_folder_name # change ownership from root to user ubuntu and group ubuntu
### The volume can be unmounted as follows ###
sudo umount work_folder_name # unmount device
~~~

<h4>Launching multinodes</h4>
TO DO

<h4>Additional AWS Help</h4>

- [EC2 instance types](https://aws.amazon.com/ec2/instance-types/)
- [EC2 User Guide](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts.html)
- [EC2 pricing](http://aws.amazon.com/ec2/pricing/)
- [EBS pricing](http://aws.amazon.com/ebs/pricing/)
- [S3 pricing](http://aws.amazon.com/s3/pricing/)

## Current Caffe uses
- [Demo](http://demo.caffe.berkeleyvision.org/): pick an URL image or give it your own
- Regions with Convolutional Neural Network Features (RCNN) finds many regions of interest and then applies Caffe to those regions
  - Ross Girshick et al., "[Rich feature hierarchies for accurate object detection and semantic segmentation](http://arxiv.org/abs/1311.2524v4)." CVPR, 2014. [code](https://github.com/rbgirshick/rcnn)
  - Ross Girshick, "[Fast R-CNN](http://arxiv.org/pdf/1504.08083v2)." ICCV, 2015. [code](https://github.com/rbgirshick/fast-rcnn/blob/master/README.md)
  - Shaoqing Ren, Kaiming He, Ross Girshick, Jian Sun, "[Faster R-CNN: towards real-time object detection](http://arxiv.org/abs/1506.01497)." NIPS, 2015. [code](https://github.com/rbgirshick/fast-rcnn/blob/master/README.m://github.com/rbgirshick/py-faster-rcnn)
- Simultenous Detection and Segmentation (SDS)
  - Each pixel has a label
  - Jonathan Long, Evan Shelhamer, Trevor Darrell, "[Fully convolutional networks for semantic segmentation](http://arxiv.org/abs/1411.4038)." CVPR, 2015
  - Similar architectures for depth estimation and for denoising

## Other Interesting Deep Learning Works
- [Clarifai demo](http://clarifai.com/): Pick an URL image/video or give it your own
- [Places demo](http://places.csail.mit.edu/demo.html)
- Input images and output captioning in natural language
  - Donague, et al., "[Long-term recurrent convolutional networks for visual recognition and description](http://arxiv.org/abs/1411.4389)." CVPR, 2015
- CNNs designed for hyperspectral classification
  -  ["Deep convolutional neural networks for hyperspectral image classification"](http://downloads.hindawi.com/journals/js/aip/258619.pdf)

## Further reading
- [Caffe homepage](http://.caffe.berkeleyvision.org/)
- Stanford Caffe [tutorial slides](http://vision.stanford.edu/teaching/cs231n/slides/caffe_tutorial.pdf)
- Liu, Ce. Neural Networks 1. Boston University. 2013
- LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey, "Deep Learning." Nature. Vol 521. 2015
- Caffe Python API [explanation](http://codrspace.com/Jaleyhd/caffe-python-tutorial/ Caffe Python API Explanation)
- CMU Caffe [tutorial](http://graphics.cs.cmu.edu/courses/16-824-S15/16824_2015/7.pptx)
- The Unreasonable Effectiveness of Recurrent Neural Networks [(A. Karpathy blog)](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) 
- Show and Tell: A Neural Image Caption Generator [paper](http://arxiv.org/pdf/1411.4555v2.pdf) 
- CVPR 2015 Jeff Donahue's Caffe [tutorial](http://tutorial.caffe.berkeleyvision.org/caffe-cvpr15-sequences.pdf): Sequences in Caffe
